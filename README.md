<img src="imgs/teaser.png">

# Domain-Specific Mappings for Generative Adversarial Style Transfer
[[Project Page]](http://acht7111020.github.io/DSMAP-demo)[[Paper]](https://arxiv.org/abs/2008.02198)

Pytorch implementation for our paper **Domain-Specific Mappings for Generative Adversarial Style Transfer**.

## Example Results
<img src="imgs/style_inter.gif">

## Paper
Domain-Specific Mappings for Generative Adversarial Style Transfer<br>
[Hsin-Yu Chang](https://github.com/acht7111020), [Zhixiang Wang](http://homepage.ntu.edu.tw/~r06944046/), and [Yung-Yu Chuang](https://www.csie.ntu.edu.tw/~cyy/)<br>
European Conference on Computer Vision (ECCV), 2020<br>
[[arxiv]](https://arxiv.org/abs/2008.02198)

## Citation
If you find the work is useful in your research, please consider citing:
```
@inproceedings{chang2020dsmap,
    author    = {Chang, Hsin-Yu and Wang Zhixiang and Chuang, Yung-Yu},
    title     = {Domain-Specific Mappings for Generative Adversarial Style Transfers},
    booktitle = {European Conference on Computer Vision},
    year      = {2020}
```

## Usage

### Requirements
1. Python 3.6 or higher
2. Pytorch 0.4.1 and torchvision
3. TensorboardX
4. Tensorflow

### Dataset
Download dataset from the following github repo.
* [Cat2Dog (DRIT)](https://github.com/HsinYingLee/DRIT)
* [Portrait (DRIT)](https://github.com/HsinYingLee/DRIT)
* [Monet (CycleGAN)](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
* [Yosemite (CycleGAN)](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

### Train & Test
Coming Soon!

# Reference
Code inspired from:
1. https://github.com/NVlabs/MUNIT
2. https://github.com/HelenMao/MSGAN

